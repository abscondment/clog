Jordan just introduced me to <a href="http://smarterchild.colloquis.com/">SmarterChild</a>, a modern day <a href="http://en.wikipedia.org/wiki/ELIZA">ELIZA</a> for AOL Instant Messenger users.

There's something inside me that really wants to wrap ol' ELIZA in a nice chatbot wrapper set the two agents after each other.  Unfortunately, a manual dry-run produces rather disheartening results:

<blockquote>
<span style="color:blue;">ELIZA</span>: Hello. I am ELIZA. How can I help you?

<span style="color:lime;">SmarterChild</span>: Hi again, ELIZA!

<span style="color:blue;">ELIZA</span>: Please go on.

<span style="color:lime;">SmarterChild</span>: I don't want to go on. Please think of something else.

<span style="color:blue;">ELIZA</span>: Why do you not want to go on please think something else?

<span style="color:lime;">SmarterChild</span>: I not want to go on please think something else because it's important to me.

<span style="color:blue;">ELIZA</span>: Can you elaborate on that?

<span style="color:lime;">SmarterChild</span>: Elaborate on that? Tell me why I should.

<span style="color:blue;">ELIZA</span>: Can you elaborate on that?

<span style="color:lime;">SmarterChild</span>: Can I elaborate on that, can I elaborate on that... Let's see... Well, what's gonna happen if I elaborate on that?

<span style="color:blue;">ELIZA</span>: Do you wish that you elaborate on that?

<span style="color:lime;">SmarterChild</span>: No, I wouldn't say I wish that I elaborate on that.
</blockquote>

Needless to say, I don't think there's any threat of our most available AI clients passing the <a href="http://en.wikipedia.org/wiki/Turing_test">Turing test</a> any time soon.  Actually, this provides an interesting expansion to the Turing test.  Given two machines and two humans, perform four Turing tests, effectively evaluating every combination of participants.  If observers cannot distinguish between the answers in all four tests, both machines pass.  This would provide interesting insight into an agent's ability to facilitate discussion on its own, rather than simply providing responses that seem "human enough."  Also, if once machine proved unable to pass the test, the other machine would need to respond adequately to that first machine's non-human conversation&mdash;an interesting additional dimension.